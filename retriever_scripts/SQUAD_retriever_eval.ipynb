{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":366563,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":303946,"modelId":324415}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModel\nfrom sklearn.neighbors import NearestNeighbors\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntop_k = 20\n\n\nencoder_path = \"/kaggle/input/distillbert_retriever/pytorch/default/1/model/encoder\"\ntokenizer_path = \"/kaggle/input/distillbert_retriever/pytorch/default/1/model/tokenizer\"\nmodel = AutoModel.from_pretrained(encoder_path).to(device).eval()\ntokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n\n\ndef embed_texts(texts, batch_size=64):\n    all_embeddings = []\n    with torch.no_grad():\n        for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding\"):\n            batch = texts[i:i+batch_size]\n            inputs = tokenizer(\n                batch,\n                padding=\"max_length\",\n                truncation=True,\n                max_length=256,\n                return_tensors=\"pt\"\n            ).to(device)\n            outputs = model(**inputs)\n            embeddings = outputs.last_hidden_state.mean(dim=1).cpu()\n            all_embeddings.append(embeddings)\n    return torch.cat(all_embeddings, dim=0).numpy()\n\n\nsquad = load_dataset(\"squad\", split=\"validation\")\nquestions = squad[\"question\"]\ncontexts  = squad[\"context\"]\n\n\ncontext_embeddings = embed_texts(contexts)\n\n\nindex = NearestNeighbors(n_neighbors=top_k, metric=\"cosine\")\nindex.fit(context_embeddings)\n\n\nquery_embeddings = embed_texts(questions)\n\n\ndistances, indices = index.kneighbors(query_embeddings, return_distance=True)\n\n\nn = len(questions)\n\nrecall_at_1 = np.mean([1 if i == idxs[0] else 0\n                       for i, idxs in enumerate(indices)])\n\n\nrecall_at_5 = np.mean([1 if i in idxs[:5] else 0\n                       for i, idxs in enumerate(indices)])\n\n\nrecall_at_20 = np.mean([1 if i in idxs else 0\n                        for i, idxs in enumerate(indices)])\n\n\nrr_scores = [1/(idx.tolist().index(i)+1) if i in idx else 0\n             for i, idx in enumerate(indices)]\nmrr = np.mean(rr_scores)\n\nprint(f\"Retriever Evaluation on SQuAD Test Set:\")\nprint(f\"  Recall@1 : {recall_at_1:.3f}\")\nprint(f\"  Recall@5 : {recall_at_5:.3f}\")\nprint(f\"  Recall@20: {recall_at_20:.3f}\")\nprint(f\"  MRR@20   : {mrr:.3f}\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-30T16:47:53.620989Z","iopub.execute_input":"2025-04-30T16:47:53.621265Z","iopub.status.idle":"2025-04-30T16:50:28.003364Z","shell.execute_reply.started":"2025-04-30T16:47:53.621246Z","shell.execute_reply":"2025-04-30T16:50:28.002554Z"}},"outputs":[{"name":"stderr","text":"Embedding: 100%|██████████| 166/166 [01:16<00:00,  2.16it/s]\nEmbedding: 100%|██████████| 166/166 [01:14<00:00,  2.23it/s]\n","output_type":"stream"},{"name":"stdout","text":"Retriever Evaluation on SQuAD Test Set:\n  Recall@1 : 0.111\n  Recall@5 : 0.499\n  Recall@20: 0.744\n  MRR@20   : 0.266\n","output_type":"stream"}],"execution_count":8}]}
